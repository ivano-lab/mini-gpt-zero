# mini-gpt-zero

Implementação de um modelo de linguagem simples inspirado na arquitetura dos Transformers (como o GPT). Este projeto serve como base para um estudo de caso acadêmico, documentando todas as etapas do desenvolvimento de um modelo de linguagem leve e open source.

## Objetivos

- Compreender os fundamentos de modelos de linguagem.
- Implementar um pequeno transformer em PyTorch.
- Treinar o modelo para prever o próximo caractere de um texto.
- Explorar como a geração de texto funciona por meio de redes neurais.
- Documentar o processo de desenvolvimento incremental como parte de um artigo científico.

## Contexto Acadêmico

Este projeto está sendo desenvolvido como parte de um artigo científico que visa analisar e documentar o processo de construção de um modelo de linguagem simplificado. O foco está na compreensão prática dos conceitos envolvidos e na análise das decisões técnicas tomadas ao longo do desenvolvimento.

## Tecnologias Utilizadas

- Python
- PyTorch
- NumPy

## Funcionalidades Implementadas

- Estrutura básica do modelo Transformer.
- Função de treinamento para previsão do próximo caractere.
- Pré-processamento simples de dados de texto.

## Roadmap

- [x] Implementação da arquitetura básica do modelo.
- [x] Função de treinamento inicial.
- [ ] Integração de datasets reais para treinamento.
- [ ] Implementação de função de geração de texto.
- [ ] Criação de visualizações para análise do aprendizado.
- [ ] Documentação detalhada de cada etapa no artigo científico.

##  Como Utilizar

1. Clone o repositório:

   ```
   git clone https://github.com/ivano-lab/mini-gpt-zero.git
   cd mini-gpt-zero
   ```

2. Instale as dependências:

   ```
   pip install torch numpy tqdm
   ```

3. Execute o script principal:

   ```
   python main.py
   ```

## Artigo Científico

O artigo associado a este projeto está em desenvolvimento e será anexado futuramente neste repositório como arquivo .pdf com o passo a passo completo do projeto e análise crítica dos resultados.

Todas as etapas estão organizadas em milestones com issues abertas para facilitar a reprodutibilidade e estruturação do artigo científico.

Você pode acompanhar o progresso em:

[Issues[(https://github.com/ivano-lab/mini-gpt-zero/issues) | [Milestones](https://github.com/ivano-lab/mini-gpt-zero/milestones) 


## Contribuições

Sinta-se à vontade para abrir issues ou pull requests com sugestões de melhorias, correções ou novas funcionalidades.

## Autor

**Ívano Fontes**

Acadêmico de <a href="https://sites.uft.edu.br/uab/index.php/graduacao/301-licenciatura-em-computacao" target="_blank"> Licenciatura em Computação - UFT</a> 

Contato: <a href="https://www.linkedin.com/in/%C3%ADvano-fontes/" target="_blank">LinkedIn</a>

## Licença

Este projeto está licenciado sob a [MIT License]()


